# Craw Data By AI

Há»‡ thá»‘ng AI-powered crawler chuyÃªn nghiá»‡p Ä‘á»ƒ crawl vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n Nháº­t Báº£n vá»›i cáº¥u trÃºc dá»¯ liá»‡u chuáº©n hÃ³a vÃ  kháº£ nÄƒng má»Ÿ rá»™ng cao.

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

- **AI-Powered Extraction**: Sá»­ dá»¥ng AI cá»§a crawl4ai Ä‘á»ƒ extract dá»¯ liá»‡u thÃ´ng minh
- **Structured Data**: Output JSON/CSV vá»›i 200+ fields theo PropertyModel chuáº©n
- **Multi-language Support**: Há»— trá»£ tiáº¿ng Nháº­t, Anh, Viá»‡t, Trung (CN/TW)
- **Smart Image Classification**: Tá»± Ä‘á»™ng phÃ¢n loáº¡i hÃ¬nh áº£nh (exterior, interior, kitchen, etc.)
- **Transportation Info**: Extract thÃ´ng tin 5 ga tÃ u gáº§n nháº¥t vá»›i Ä‘áº§y Ä‘á»§ phÆ°Æ¡ng tiá»‡n
- **Comprehensive Amenities**: Detect 50+ tiá»‡n nghi vÃ  Ä‘áº·c Ä‘iá»ƒm cÄƒn há»™
- **Modular Architecture**: Cáº¥u trÃºc package rÃµ rÃ ng, dá»… báº£o trÃ¬ vÃ  má»Ÿ rá»™ng
- **Batch Processing**: Crawl nhiá»u properties cÃ¹ng lÃºc vá»›i hiá»‡u suáº¥t cao
- **Statistics & Reports**: Táº¡o bÃ¡o cÃ¡o thá»‘ng kÃª tá»± Ä‘á»™ng

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
â”œâ”€â”€ crawler/                    # Package crawler chÃ­nh
â”‚   â”œâ”€â”€ __init__.py            # Export cÃ¡c class chÃ­nh
â”‚   â”œâ”€â”€ config.py              # Cáº¥u hÃ¬nh crawler
â”‚   â”œâ”€â”€ data_schema.py         # Schema vÃ  cáº¥u trÃºc dá»¯ liá»‡u
â”‚   â”œâ”€â”€ html_parser.py         # Parse HTML vÃ  extract dá»¯ liá»‡u
â”‚   â”œâ”€â”€ markdown_parser.py     # Parse markdown content
â”‚   â”œâ”€â”€ image_extractor.py     # Xá»­ lÃ½ extract hÃ¬nh áº£nh
â”‚   â”œâ”€â”€ property_extractor.py  # Logic chÃ­nh extract dá»¯ liá»‡u property
â”‚   â”œâ”€â”€ property_crawler.py    # Crawler chÃ­nh
â”‚   â”œâ”€â”€ utils.py               # CÃ¡c utility functions
â”‚   â””â”€â”€ README.md              # TÃ i liá»‡u package
â”œâ”€â”€ index.py                   # File demo Ä‘Æ¡n giáº£n
â”œâ”€â”€ models.py                  # Pydantic models (200+ fields)
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ structure.json             # MÃ´ táº£ chi tiáº¿t 200+ fields
â”œâ”€â”€ FIELD_MANAGEMENT_GUIDE.md  # HÆ°á»›ng dáº«n thÃªm/xÃ³a trÆ°á»ng
â””â”€â”€ README.md                  # HÆ°á»›ng dáº«n nÃ y
```

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. Táº¡o mÃ´i trÆ°á»ng Python 3.10
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# hoáº·c
source venv/bin/activate  # Linux/Mac
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 3. Thiáº¿t láº­p crawl4ai
```bash
crawl4ai-setup
```

### 4. Kiá»ƒm tra thiáº¿t láº­p
```bash
crawl4ai-doctor
```

## ğŸ¯ CÃ¡ch sá»­ dá»¥ng

### 1. Demo nhanh (file Ä‘Æ¡n giáº£n)
```bash
python index.py
```

### 2. Sá»­ dá»¥ng package crawler (khuyáº¿n nghá»‹)

#### Crawl
```python
import asyncio
from crawler import EnhancedPropertyCrawler

async def main():
    urls = [
        "https://example.com/property/123",
        "https://example.com/property/456",
        "https://example.com/property/789"
    ]
    
    crawler = EnhancedPropertyCrawler()
    results = await crawler.crawl_multiple_properties(urls)
    
    # LÆ°u káº¿t quáº£
    json_file = crawler.save_results_to_json(results)
    csv_file = crawler.save_results_to_csv(results)
    
    print(f"ÄÃ£ lÆ°u JSON: {json_file}")
    print(f"ÄÃ£ lÆ°u CSV: {csv_file}")

asyncio.run(main())
```

### 3. Import trá»±c tiáº¿p cÃ¡c module
```python
from crawler import EnhancedPropertyCrawler, PropertyExtractor
from crawler.config import CrawlerConfig
from crawler.utils import create_property_model
```

## ğŸ—ï¸ PropertyModel Structure (200+ Fields)

Há»‡ thá»‘ng sá»­ dá»¥ng cáº¥u trÃºc dá»¯ liá»‡u chuáº©n hÃ³a vá»›i 200+ trÆ°á»ng dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n nhÃ³m rÃµ rÃ ng:

### ğŸ“ ThÃ´ng tin Ä‘á»‹a chá»‰
- `postcode`: MÃ£ bÆ°u Ä‘iá»‡n
- `prefecture`: Tá»‰nh (æ±äº¬éƒ½, å¤§é˜ªåºœ, etc.)
- `city`: ThÃ nh phá»‘
- `district`: Quáº­n/phÆ°á»ng
- `chome_banchi`: Sá»‘ khá»‘i vÃ  lÃ´ (há»‡ thá»‘ng Ä‘á»‹a chá»‰ Nháº­t)

### ğŸ¢ ThÃ´ng tin tÃ²a nhÃ 
- `building_name_ja/en/zh_CN/zh_TW`: TÃªn tÃ²a nhÃ  Ä‘a ngÃ´n ngá»¯
- `building_type`: Loáº¡i tÃ²a nhÃ  (chung cÆ°, nhÃ  riÃªng)
- `building_description_*`: MÃ´ táº£ tÃ²a nhÃ  Ä‘a ngÃ´n ngá»¯
- `year`: NÄƒm xÃ¢y dá»±ng
- `floors`: Sá»‘ táº§ng
- `num_units`: Sá»‘ cÄƒn há»™ trong tÃ²a nhÃ 
- `structure`: Loáº¡i cáº¥u trÃºc (thÃ©p, gá»—, khÃ¡c)

### ğŸ  ThÃ´ng tin cÄƒn há»™
- `room_type`: Loáº¡i phÃ²ng (1K, 1DK, 2LDK, etc.)
- `size`: Diá»‡n tÃ­ch (mÂ²)
- `floor_no`: Sá»‘ táº§ng cá»§a cÄƒn há»™
- `unit_no`: Sá»‘ cÄƒn há»™
- `balcony_size`: Diá»‡n tÃ­ch ban cÃ´ng

### ğŸ’° ThÃ´ng tin tÃ i chÃ­nh
- `monthly_rent`: Tiá»n thuÃª hÃ ng thÃ¡ng
- `monthly_maintenance`: PhÃ­ báº£o trÃ¬ hÃ ng thÃ¡ng
- `months_deposit/numeric_deposit`: Tiá»n Ä‘áº·t cá»c
- `months_key/numeric_key`: Tiá»n chÃ¬a khÃ³a
- `fire_insurance`: PhÃ­ báº£o hiá»ƒm chÃ¡y ná»•
- `other_initial_fees`: CÃ¡c phÃ­ ban Ä‘áº§u khÃ¡c

### ğŸš‡ Giao thÃ´ng (5 ga gáº§n nháº¥t)
- `station_name_1/2/3/4/5`: TÃªn ga tÃ u
- `train_line_name_1/2/3/4/5`: TÃªn tuyáº¿n tÃ u
- `walk_1/2/3/4/5`: Thá»i gian Ä‘i bá»™ (phÃºt)
- `bus_1/2/3/4/5`: Thá»i gian Ä‘i xe buÃ½t (phÃºt)
- `car_1/2/3/4/5`: Thá»i gian Ä‘i Ã´ tÃ´ (phÃºt)
- `cycle_1/2/3/4/5`: Thá»i gian Ä‘i xe Ä‘áº¡p (phÃºt)

### ğŸ¢ Tiá»‡n Ã­ch tÃ²a nhÃ 
- `autolock`: KhÃ³a tá»± Ä‘á»™ng (Y/N)
- `elevator`: Thang mÃ¡y (Y/N)
- `parking`: Chá»— Ä‘áº­u xe (Y/N)
- `bicycle_parking`: Chá»— Ä‘áº­u xe Ä‘áº¡p (Y/N)
- `delivery_box`: Há»™p giao hÃ ng (Y/N)
- `concierge`: Dá»‹ch vá»¥ lá»… tÃ¢n (Y/N)
- `gym`: PhÃ²ng táº­p thá»ƒ dá»¥c (Y/N)
- `swimming_pool`: Há»“ bÆ¡i (Y/N)

### ğŸ  Tiá»‡n nghi cÄƒn há»™ (50+ items)
- `aircon`: Äiá»u hÃ²a khÃ´ng khÃ­ (Y/N)
- `internet_wifi`: WiFi (Y/N)
- `system_kitchen`: Báº¿p há»‡ thá»‘ng (Y/N)
- `washer_dryer`: MÃ¡y giáº·t/sáº¥y (Y/N)
- `bath`: Bá»“n táº¯m (Y/N)
- `separate_toilet`: Toilet riÃªng biá»‡t (Y/N)
- `balcony`: Ban cÃ´ng (Y/N)
- `storage`: Kho chá»©a (Y/N)
- ... vÃ  40+ tiá»‡n nghi khÃ¡c

### ğŸ§­ HÆ°á»›ng cÄƒn há»™
- `facing_north/south/east/west`: HÆ°á»›ng báº¯c/nam/Ä‘Ã´ng/tÃ¢y (Y/N)
- `facing_northeast/southeast/southwest/northwest`: HÆ°á»›ng chÃ©o (Y/N)

### ğŸ“¸ HÃ¬nh áº£nh (16 slots)
- `image_category_1-16`: Danh má»¥c hÃ¬nh áº£nh
- `image_url_1-16`: URL hÃ¬nh áº£nh

### ğŸ“ Tá»a Ä‘á»™ & Links
- `map_lat`: VÄ© Ä‘á»™
- `map_lng`: Kinh Ä‘á»™
- `youtube`: Link video YouTube
- `vr_link`: Link tour thá»±c táº¿ áº£o

> **Chi tiáº¿t Ä‘áº§y Ä‘á»§**: Xem file `structure.json` Ä‘á»ƒ biáº¿t mÃ´ táº£ chi tiáº¿t táº¥t cáº£ 200+ trÆ°á»ng dá»¯ liá»‡u

## ğŸ“Š Sample Output

```json
{
  "success": true,
  "url": "https://example.com/property/123",
  "property_data": {
    "property_csv_id": "PROP_123",
    "building_name_ja": "ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ³ã‚·ãƒ§ãƒ³",
    "building_type": "Apartment",
    "prefecture": "æ±äº¬éƒ½",
    "city": "æ¸‹è°·åŒº",
    "room_type": "1K",
    "size": 25.5,
    "monthly_rent": 120000,
    "station_name_1": "æ¸‹è°·é§…",
    "train_line_name_1": "JRå±±æ‰‹ç·š",
    "walk_1": 5,
    "aircon": "Y",
    "elevator": "Y",
    "images": [
      {
        "category": "exterior",
        "url": "https://example.com/image1.jpg"
      }
    ],
    "map_lat": 35.6762,
    "map_lng": 139.6503
  }
}
```

## ğŸ¤– AI Configuration

Há»‡ thá»‘ng sá»­ dá»¥ng AI Ä‘á»ƒ extract dá»¯ liá»‡u thÃ´ng minh vá»›i cÃ¡c tÃ­nh nÄƒng:

- **Schema-based**: Extract theo cáº¥u trÃºc PropertyModel chuáº©n
- **Smart Conversion**: Tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i ä¸‡å†† â†’ yen, åª â†’ mÂ²
- **Context-aware**: Hiá»ƒu ngá»¯ cáº£nh tiáº¿ng Nháº­t vÃ  Ä‘a ngÃ´n ngá»¯
- **Modular Processing**: TÃ¡ch biá»‡t HTML parser vÃ  Markdown parser

### Cáº¥u hÃ¬nh AI Provider

Trong `crawler/config.py`:

```python
# Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh (Ollama local)
CRAWLER_CONFIG = {
    "ai_provider": "ollama/llama3.2",
    "api_token": None,  # KhÃ´ng cáº§n token cho Ollama
    # ...
}

# Sá»­ dá»¥ng OpenAI
CRAWLER_CONFIG = {
    "ai_provider": "openai/gpt-4",
    "api_token": "your-openai-api-key",
    # ...
}

# Sá»­ dá»¥ng Claude
CRAWLER_CONFIG = {
    "ai_provider": "anthropic/claude-3",
    "api_token": "your-anthropic-api-key",
    # ...
}
```

## ğŸ“ˆ Statistics & Reports

Tá»± Ä‘á»™ng táº¡o bÃ¡o cÃ¡o thá»‘ng kÃª:

```json
{
  "summary": {
    "total_properties": 100,
    "successful_crawls": 95,
    "success_rate": "95.0%"
  },
  "statistics": {
    "building_types": {"Apartment": 80, "House": 15},
    "prefectures": {"æ±äº¬éƒ½": 60, "å¤§é˜ªåºœ": 25},
    "price_ranges": {"50k_100k": 40, "100k_200k": 35},
    "amenities": {"aircon": 90, "elevator": 75}
  }
}
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p:

1. **"Failed to extract content"**
   - Kiá»ƒm tra crawl4ai-setup: `crawl4ai-setup`
   - Kiá»ƒm tra internet connection
   - Thá»­ URL khÃ¡c

2. **"AI provider error"**
   - Kiá»ƒm tra Ollama Ä‘Ã£ cháº¡y: `ollama serve`
   - Hoáº·c thay Ä‘á»•i provider trong `crawler/config.py`

3. **"Timeout error"**
   - TÄƒng page_timeout trong `crawler/config.py`
   - Kiá»ƒm tra tá»‘c Ä‘á»™ máº¡ng

4. **"Import error"**
   - Kiá»ƒm tra package Ä‘Ã£ cÃ i Ä‘Ãºng: `pip install -r requirements.txt`
   - Kiá»ƒm tra Python path

### Debug mode:

```python
# ThÃªm vÃ o script cá»§a báº¡n
import logging
logging.basicConfig(level=logging.DEBUG)

# Hoáº·c sá»­ dá»¥ng config debug
from crawler.config import CrawlerConfig
config = CrawlerConfig()
config.debug = True
```

### Kiá»ƒm tra cáº¥u trÃºc package:

```bash
# Test syntax
python -c "from models import PropertyModel; print('âœ… Models OK')"
python -c "from crawler import EnhancedPropertyCrawler; print('âœ… Crawler OK')"

# Test data structure  
python -c "from crawler.data_schema import PropertyDataSchema; data = PropertyDataSchema.get_empty_property_data('test'); print(f'âœ… {len(data)} fields')"
```

## ğŸš¨ LÆ°u Ã½ quan trá»ng

1. **Rate Limiting**: ThÃªm delay giá»¯a requests
2. **Legal Compliance**: TuÃ¢n thá»§ robots.txt vÃ  ToS
3. **Resource Usage**: AI extraction tá»‘n tÃ i nguyÃªn
4. **Data Accuracy**: LuÃ´n verify dá»¯ liá»‡u quan trá»ng

## ğŸ¯ Roadmap

- [x] âœ… Cáº¥u trÃºc package modular
- [x] âœ… Há»— trá»£ 200+ fields chuáº©n hÃ³a
- [x] âœ… Export JSON/CSV
- [x] âœ… Multi-language support (4 ngÃ´n ngá»¯)
- [x] âœ… Comprehensive field management guide
- [ ] ğŸ”„ Dashboard web interface
- [ ] ğŸ”„ Real-time monitoring
- [ ] ğŸ”„ Multi-threading optimization
- [ ] ğŸ”„ Há»— trá»£ thÃªm website báº¥t Ä‘á»™ng sáº£n
- [ ] ğŸ”„ API REST endpoints
- [ ] ğŸ”„ Docker containerization

## ğŸ“š TÃ i liá»‡u bá»• sung

- **[FIELD_MANAGEMENT_GUIDE.md](FIELD_MANAGEMENT_GUIDE.md)**: HÆ°á»›ng dáº«n thÃªm/xÃ³a trÆ°á»ng dá»¯ liá»‡u
- **[crawler/README.md](crawler/README.md)**: TÃ i liá»‡u chi tiáº¿t vá» package crawler
- **[structure.json](structure.json)**: MÃ´ táº£ Ä‘áº§y Ä‘á»§ 200+ fields
- **[models.py](models.py)**: Pydantic models definition

---