# H∆∞·ªõng D·∫´n Th√™m/X√≥a Tr∆∞·ªùng - Property Crawler

## üìã C·∫•u Tr√∫c Files C·∫ßn S·ª≠a

```
models.py                    # Pydantic models
crawler/data_schema.py       # Data structure & keywords  
crawler/html_parser.py       # HTML extraction logic
crawler/markdown_parser.py   # Markdown extraction logic
crawler/property_extractor.py # Main extraction orchestrator
```

## ‚ûï Th√™m Tr∆∞·ªùng M·ªõi

### B∆∞·ªõc 1: models.py
```python
# Th√™m field v√†o PropertyModel
security_system: Optional[Literal['Y', 'N']] = Field(None, description="C√≥ h·ªá th·ªëng an ninh kh√¥ng?")
```

### B∆∞·ªõc 2: crawler/data_schema.py
```python
# Th√™m v√†o get_empty_property_data()
return {
    # ... existing fields ...
    'security_system': None,
}

# N·∫øu l√† amenity, th√™m keywords
AMENITY_KEYWORDS = {
    # ... existing keywords ...
    'security_system': ['„Çª„Ç≠„É•„É™„ÉÜ„Ç£', 'security', 'Èò≤ÁäØ„Ç∑„Çπ„ÉÜ„É†'],
}
```

### B∆∞·ªõc 3: crawler/html_parser.py
```python
# Th√™m method extract ho·∫∑c c·∫≠p nh·∫≠t existing method
def extract_security_from_html(self, html: str, property_data: Dict[str, Any]) -> Dict[str, Any]:
    if re.search(r'„Çª„Ç≠„É•„É™„ÉÜ„Ç£|security|Èò≤ÁäØ', html, re.IGNORECASE):
        property_data['security_system'] = 'Y'
    return property_data
```

### B∆∞·ªõc 4: crawler/property_extractor.py
```python
# G·ªçi method extract m·ªõi
def extract_comprehensive_data(self, url: str, html_content: str, markdown_content: str) -> Dict[str, Any]:
    # ... existing code ...
    property_data = self.html_parser.extract_security_from_html(html_content, property_data)
    return property_data
```

## ‚ûñ X√≥a Tr∆∞·ªùng

### B∆∞·ªõc 1: models.py
```python
# Comment ho·∫∑c x√≥a field
# bs: Optional[Literal['Y', 'N']] = Field(None, description="...")
```

### B∆∞·ªõc 2: crawler/data_schema.py
```python
# X√≥a kh·ªèi get_empty_property_data()
return {
    # 'bs': None,  # X√≥a d√≤ng n√†y
}

# X√≥a keywords (n·∫øu c√≥)
AMENITY_KEYWORDS = {
    # 'bs': ['BS', 'BSÊîæÈÄÅ'],  # X√≥a d√≤ng n√†y
}
```

### B∆∞·ªõc 3: crawler/html_parser.py
```python
# X√≥a logic extract
# if re.search(r'BS|satellite', html, re.IGNORECASE):
#     property_data['bs'] = 'Y'
```

### B∆∞·ªõc 4: crawler/property_extractor.py
```python
# X√≥a method call (n·∫øu c√≥)
# property_data = self.html_parser.extract_bs_from_html(html_content, property_data)
```

## üß™ Test Nhanh

```bash
# Test syntax
python -c "from models import PropertyModel; print('‚úÖ Models OK')"
python -c "from crawler import EnhancedPropertyCrawler; print('‚úÖ Crawler OK')"

# Test data structure
python -c "from crawler.data_schema import PropertyDataSchema; data = PropertyDataSchema.get_empty_property_data('test'); print(f'‚úÖ {len(data)} fields')"
```

## üîß C√°c Lo·∫°i Tr∆∞·ªùng Th∆∞·ªùng D√πng

```python
# Boolean Y/N
field_name: Optional[Literal['Y', 'N']] = Field(None, description="...")

# Text
field_name: Optional[str] = Field(None, description="...")

# Enum
field_name: Optional[Literal['option1', 'option2']] = Field(None, description="...")
```

## üö® L∆∞u √ù

- **Backup tr∆∞·ªõc khi s·ª≠a**: `copy models.py models.py.backup`
- **ƒê·∫∑t t√™n**: D√πng `snake_case`, t√™n c√≥ √Ω nghƒ©a
- **Default value**: Lu√¥n ƒë·ªÉ `None`
- **Test k·ªπ**: Ch·∫°y test sau m·ªói thay ƒë·ªïi

## ÔøΩ V·ªã Tr√≠ Th√™m Theo Nh√≥m

**ƒê·ªãa ch·ªâ**: Sau `'chome_banchi': None,`
**T√≤a nh√†**: Sau `'year': None,`
**Ga t√†u**: Sau c√°c station fields
**Ti·ªán √≠ch t√≤a nh√†**: Sau `'ur': None,`
**Ti·ªán nghi cƒÉn h·ªô**: Sau `'yard': None,`

---
*C·∫≠p nh·∫≠t: C·∫•u tr√∫c package crawler m·ªõi*