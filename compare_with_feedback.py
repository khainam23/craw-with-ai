#!/usr/bin/env python3
"""
Script Ä‘á»ƒ so sÃ¡nh káº¿t quáº£ crawl vá»›i feedback
"""

import json
from typing import Dict, Any

def load_latest_crawl_result() -> Dict[str, Any]:
    """Load káº¿t quáº£ crawl má»›i nháº¥t"""
    import glob
    import os
    
    # TÃ¬m file crawl_results má»›i nháº¥t
    pattern = "crawl_results_*.json"
    files = glob.glob(pattern)
    if not files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file crawl results")
        return {}
    
    latest_file = max(files, key=os.path.getctime)
    print(f"ğŸ“ Loading: {latest_file}")
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if data and len(data) > 0 and data[0].get('success'):
        return data[0]['property_data']
    return {}

def compare_with_feedback(crawl_data: Dict[str, Any]):
    """So sÃ¡nh vá»›i feedback tá»« feedback.txt"""
    
    print("\n" + "="*80)
    print("ğŸ” SO SÃNH Káº¾T QUáº¢ CRAWL Vá»šI FEEDBACK")
    print("="*80)
    
    # Feedback data tá»« feedback.txt
    feedback_comparisons = [
        {
            'field': 'Äá»‹a chá»‰',
            'crawl_key': ['prefecture', 'district', 'chome_banchi'],
            'crawl_expected': 'æ±äº¬éƒ½ç·´é¦¬åŒºæ¡œå°ä¸‰ä¸ç›®ï¼’ï¼ç•ªï¼“å·',
            'website_actual': 'æ±äº¬éƒ½ç·´é¦¬åŒºæ¡œå°ä¸‰ä¸ç›®ï¼’ï¼ç•ªï¼“å·',
            'issue': 'Crawl thiáº¿u chi tiáº¿t sá»‘ nhÃ  vÃ  khu phá»‘'
        },
        {
            'field': 'Postcode',
            'crawl_key': 'postcode',
            'crawl_expected': '107-0052',
            'website_actual': 'KhÃ´ng hiá»ƒn thá»‹ trá»±c tiáº¿p trÃªn web',
            'issue': 'KhÃ´ng kiá»ƒm chá»©ng Ä‘Æ°á»£c'
        },
        {
            'field': 'Loáº¡i tÃ²a nhÃ ',
            'crawl_key': ['building_type', 'structure'],
            'crawl_expected': 'ãƒãƒ³ã‚·ãƒ§ãƒ³',
            'website_actual': 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆé€  åœ°ä¸Š3éšå»º',
            'issue': 'Crawl chá»‰ ghi "ãƒãƒ³ã‚·ãƒ§ãƒ³", web chi tiáº¿t cáº¥u trÃºc'
        },
        {
            'field': 'TÃªn tÃ²a (EN/JA)',
            'crawl_key': 'building_name_ja',
            'crawl_expected': 'PLANE SOCIEï¼‹ SAKURADAI 1éšï¼‘ï¼ï¼‘',
            'website_actual': 'PLANE SOCIEï¼‹ SAKURADAI 1éšï¼‘ï¼ï¼‘',
            'issue': 'Khá»›p'
        },
        {
            'field': 'Ga gáº§n nháº¥t',
            'crawl_key': ['station_name_1', 'station_name_2', 'walk_1', 'walk_2'],
            'crawl_expected': 'æ–°æ¡œå°é§… (6 phÃºt Ä‘i bá»™)',
            'website_actual': 'æ–°æ¡œå°é§… (6 phÃºt Ä‘i bá»™), æ°·å·å°é§… (8 phÃºt Ä‘i bá»™)',
            'issue': 'Crawl thiáº¿u ga thá»© hai'
        },
        {
            'field': 'Sá»‘ táº§ng',
            'crawl_key': 'floors',
            'crawl_expected': '3',
            'website_actual': 'åœ°ä¸Š3éšå»º',
            'issue': 'Khá»›p vá» tá»•ng sá»‘ táº§ng'
        },
        {
            'field': 'Diá»‡n tÃ­ch',
            'crawl_key': 'size',
            'crawl_expected': '31.71ã¡',
            'website_actual': '31.71ã¡',
            'issue': 'Khá»›p'
        },
        {
            'field': 'NgÃ y cÃ³ sáºµn',
            'crawl_key': 'available_from',
            'crawl_expected': 'ç›¸è«‡',
            'website_actual': '10æœˆä¸­æ—¬',
            'issue': 'Crawl khÃ´ng chÃ­nh xÃ¡c'
        },
        {
            'field': 'BÃ£i Ä‘á»— xe',
            'crawl_key': 'parking',
            'crawl_expected': 'Y',
            'website_actual': 'ç„¡',
            'issue': 'Sai, web khÃ´ng cÃ³ bÃ£i Ä‘á»— xe'
        },
        {
            'field': 'BÃ£i xe mÃ¡y',
            'crawl_key': 'motorcycle_parking',
            'crawl_expected': 'Y',
            'website_actual': 'KhÃ´ng tháº¥y thÃ´ng tin',
            'issue': 'Crawl cÃ³ thá»ƒ thÃªm tá»± Ä‘á»™ng'
        }
    ]
    
    for comparison in feedback_comparisons:
        print(f"\nğŸ“‹ {comparison['field']}:")
        print(f"   ğŸ¯ Website thá»±c táº¿: {comparison['website_actual']}")
        
        # Get crawl value
        crawl_keys = comparison['crawl_key']
        if isinstance(crawl_keys, str):
            crawl_keys = [crawl_keys]
        
        crawl_values = []
        for key in crawl_keys:
            value = crawl_data.get(key)
            if value:
                crawl_values.append(f"{key}: {value}")
        
        crawl_result = " | ".join(crawl_values) if crawl_values else "âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u"
        print(f"   ğŸ¤– Crawl hiá»‡n táº¡i: {crawl_result}")
        
        # Status
        if comparison['issue'] == 'Khá»›p':
            print(f"   âœ… Tráº¡ng thÃ¡i: {comparison['issue']}")
        else:
            print(f"   âš ï¸  Váº¥n Ä‘á»: {comparison['issue']}")
    
    print("\n" + "="*80)
    print("ğŸ“Š Tá»”NG Káº¾T Cáº¢I THIá»†N")
    print("="*80)
    
    # TÃ­nh toÃ¡n cáº£i thiá»‡n
    total_fields = len(feedback_comparisons)
    improved_fields = 0
    
    for comparison in feedback_comparisons:
        if comparison['field'] in ['Loáº¡i tÃ²a nhÃ ', 'Äá»‹a chá»‰']:
            # Check if we have more detailed structure info
            if crawl_data.get('structure') and 'é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆé€ ' in crawl_data.get('structure', ''):
                improved_fields += 0.5
            if crawl_data.get('chome_banchi'):
                improved_fields += 0.5
        elif comparison['issue'] == 'Khá»›p':
            improved_fields += 1
    
    print(f"âœ… ÄÃ£ cáº£i thiá»‡n: {improved_fields}/{total_fields} fields")
    print(f"ğŸ“ˆ Tá»· lá»‡ chÃ­nh xÃ¡c: {improved_fields/total_fields*100:.1f}%")
    
    # Recommendations
    print("\nğŸ”§ KHUYáº¾N NGHá»Š Cáº¢I THIá»†N:")
    remaining_issues = [comp for comp in feedback_comparisons if comp['issue'] != 'Khá»›p']
    for issue in remaining_issues[:3]:  # Top 3 issues
        print(f"   â€¢ {issue['field']}: {issue['issue']}")

def main():
    """Main function"""
    crawl_data = load_latest_crawl_result()
    if not crawl_data:
        print("âŒ KhÃ´ng thá»ƒ load dá»¯ liá»‡u crawl")
        return
    
    compare_with_feedback(crawl_data)

if __name__ == "__main__":
    main()