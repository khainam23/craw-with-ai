"""
Custom Configuration - Optimized version with better performance and structure
"""
import re
import requests
from typing import Dict, Any, Optional, Tuple
from functools import lru_cache
from ..custom_rules import CustomExtractor
from pyproj import CRS, Transformer

# ============================================================================
# CONSTANTS AND CONFIGURATIONS
# ============================================================================

# Coordinate conversion constants
COORDINATE_OFFSET_LAT = -1.291213
COORDINATE_OFFSET_LON = -5.82497
DEFAULT_ZONE = 9
MAX_IMAGES = 16
GALLERY_TIMEOUT = 5

# Default amenities configuration
DEFAULT_AMENITIES = {
    'credit_card': 'Y',
    'no_guarantor': 'Y', 
    'aircon': 'Y',
    'aircon_heater': 'Y',
    'bs': 'Y',
    'cable': 'Y',
    'internet_broadband': 'Y',
    'internet_wifi': 'Y',
    'phoneline': 'Y',
    'flooring': 'Y',
    'system_kitchen': 'Y',
    'bath': 'Y',
    'shower': 'Y',
    'unit_bath': 'Y',
    'western_toilet': 'Y',
    'fire_insurance': 20000,
}

# Direction mapping
DIRECTION_MAPPING = {
    'åŒ—': 'facing_north',
    'åŒ—æ±': 'facing_northeast', 
    'æ±': 'facing_east',
    'æ±å—': 'facing_southeast',
    'å—': 'facing_south',
    'å—è¥¿': 'facing_southwest',
    'è¥¿': 'facing_west',
    'è¥¿åŒ—': 'facing_northwest',
    'åŒ—è¥¿': 'facing_northwest'
}

# Amenities mapping
AMENITIES_MAPPING = {
    'ãƒ•ãƒ­ãƒ³ãƒˆ': 'concierge',
    'å®…é…ãƒ­ãƒƒã‚«ãƒ¼': 'delivery_box',
    'ã‚ªãƒ¼ãƒˆãƒ­ãƒƒã‚¯': 'autolock',
    'ãƒã‚¤ã‚¯ç½®å ´': 'motorcycle_parking',
    'æ•·åœ°å†…ã”ã¿ç½®å ´': 'cleaning_service',
    'ã‚¨ãƒ¬ãƒ™ãƒ¼ã‚¿': 'elevator',
    '24æ™‚é–“ç®¡ç†': 'cleaning_service',
    'é˜²çŠ¯ã‚«ãƒ¡ãƒ©': 'autolock',
    'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚·ã‚¹ãƒ†ãƒ ': 'autolock',
    'ãƒãƒ«ã‚³ãƒ‹ãƒ¼': 'balcony',
    'ãƒã‚¹ãƒˆã‚¤ãƒ¬': 'unit_bath',
    'æ´—é¢æ‰€ç‹¬ç«‹': 'separate_toilet',
    'å®¤å†…æ´—æ¿¯æ©Ÿç½®å ´': 'washing_machine',
    'ãƒã‚¹æœ‰': 'bath',
    'æµ´å®¤ä¹¾ç‡¥æ©Ÿ': 'bath_water_heater',
    'çµ¦æ¹¯è¿½ã„ç„šãæœ‰': 'auto_fill_bath',
    'ã‚­ãƒƒãƒãƒ³æœ‰': 'system_kitchen',
    'ã‚³ãƒ³ãƒ­æœ‰': 'range',
    'ã‚°ãƒªãƒ«': 'oven',
    'ã‚ªãƒ¼ãƒ—ãƒ³': 'counter_kitchen',
    'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ': 'internet_broadband',
    'BS': 'bs',
    'CS': 'cable',
    'ãƒ”ã‚¢ãƒå¯': 'furnished',
    'ã‚¦ã‚©ãƒ¼ã‚¯ã‚¤ãƒ³ã‚¯ãƒ­ã‚¼ãƒƒãƒˆ': 'storage',
    'ãƒšãƒƒãƒˆå¯': 'pets',
    'ã‚¨ã‚¢ã‚³ãƒ³': 'aircon',
    'ãƒ•ãƒ­ãƒ¼ãƒªãƒ³ã‚°': 'flooring',
    'ã‚·ã‚¹ãƒ†ãƒ ã‚­ãƒƒãƒãƒ³': 'system_kitchen',
    'ã‚·ãƒ£ãƒ¯ãƒ¼': 'shower',
    'ã‚¬ã‚¹': 'gas',
    'WiFi': 'internet_wifi',
    'Wi-Fi': 'internet_wifi',
    'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ›ãƒ³': 'autolock',
    'TVãƒ¢ãƒ‹ã‚¿ãƒ¼ä»˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ›ãƒ³': 'autolock',
    'å®…é…BOX': 'delivery_box',
    'ã‚´ãƒŸç½®å ´': 'cleaning_service',
    'æ¸©æ°´æ´—æµ„ä¾¿åº§': 'washlet',
    'åºŠæš–æˆ¿': 'underfloor_heating',
    'é£Ÿå™¨æ´—ã„ä¹¾ç‡¥æ©Ÿ': 'dishwasher',
    'IHã‚¯ãƒƒã‚­ãƒ³ã‚°ãƒ’ãƒ¼ã‚¿ãƒ¼': 'induction_cooker',
    'è¿½ã„ç„šãæ©Ÿèƒ½': 'auto_fill_bath',
    'å®…é…ãƒœãƒƒã‚¯ã‚¹': 'delivery_box',
    'ã‚ªãƒ¼ãƒ«é›»åŒ–': 'all_electric',
    'ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚­ãƒƒãƒãƒ³': 'counter_kitchen',
    'ãƒ­ãƒ•ãƒˆ': 'loft',
    'ãƒ«ãƒ¼ãƒ•ãƒãƒ«ã‚³ãƒ‹ãƒ¼': 'roof_balcony',
    'ãƒ™ãƒ©ãƒ³ãƒ€': 'veranda',
    'åº­': 'yard',
    'SOHOå¯': 'soho',
    'å¥³æ€§é™å®š': 'female_only',
    'å­¦ç”Ÿå¯': 'student_friendly',
}

# ============================================================================
# CACHED UTILITIES
# ============================================================================

@lru_cache(maxsize=32)
def get_coordinate_transformer(zone: int = DEFAULT_ZONE) -> Transformer:
    """Get cached coordinate transformer for better performance"""
    epsg_code = 30160 + zone
    crs_xy = CRS.from_epsg(epsg_code)
    crs_wgs84 = CRS.from_epsg(4326)
    return Transformer.from_crs(crs_xy, crs_wgs84, always_xy=True)

@lru_cache(maxsize=128)
def compile_regex(pattern: str, flags: int = re.DOTALL | re.IGNORECASE) -> re.Pattern:
    """Cache compiled regex patterns for better performance"""
    return re.compile(pattern, flags)

# ============================================================================
# CORE UTILITIES
# ============================================================================

class RequestsSession:
    """Singleton requests session for connection pooling"""
    _instance = None
    _session = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._session = requests.Session()
            cls._session.headers.update({'User-Agent': 'Mozilla/5.0 (compatible; crawler)'})
        return cls._instance
    
    def get(self, url: str, **kwargs) -> requests.Response:
        return self._session.get(url, **kwargs)

# Global session instance
session = RequestsSession()

# ============================================================================
# COORDINATE CONVERSION
# ============================================================================

def xy_to_latlon_tokyo(x: float, y: float, zone: int = DEFAULT_ZONE) -> Tuple[float, float]:
    """
    Optimized coordinate conversion with cached transformer
    """
    transformer = get_coordinate_transformer(zone)
    lon, lat = transformer.transform(x, y)
    return lat + COORDINATE_OFFSET_LAT, lon + COORDINATE_OFFSET_LON

def parse_japanese_address(address: str) -> dict:
    """Parse Japanese address to extract chome_banchi"""
    if not address:
        return {"chome_banchi": None}
    
    # Use cached regex
    pattern = compile_regex(r'^(?:.*?[éƒ½é“åºœçœŒ])?(?:.*?[å¸‚åŒºç”ºæ‘])?(.*)$')
    match = pattern.match(address)
    
    return {
        "chome_banchi": match.group(1).strip() if match else None
    }

# ============================================================================
# HTML UTILITIES
# ============================================================================

def find(pattern: str, html: str) -> Optional[str]:
    """Find pattern in HTML with cached regex"""
    regex = compile_regex(pattern)
    match = regex.search(html)
    return match.group(1).strip() if match else None

def clean_html(text: str) -> str:
    """Remove HTML tags and clean text"""
    if not text:
        return ""
    # Use cached regex for HTML tag removal
    html_tag_regex = compile_regex(r'<[^>]+>')
    cleaned = html_tag_regex.sub('', text).strip()
    # Clean HTML entities
    cleaned = cleaned.replace('&nbsp;', ' ').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
    return cleaned

def setup_custom_extractor() -> CustomExtractor:
    """
    Setup optimized custom extractor with better performance and structure
    """
    extractor = CustomExtractor()
    
    # Wrapper for error handling
    def safe_wrapper(callback):
        """Wrapper for safe processing with error handling"""
        def wrapper_func(data: Dict[str, Any]) -> Dict[str, Any]:
            html = data.get('_html', '')
            if not html:
                return data
            
            try:
                return callback(data, html)
            except Exception as e:
                print(f"âŒ Error in {callback.__name__}: {e}")
                return data
        
        return wrapper_func
    
    # Chuyá»ƒn Ä‘á»•i tá»a Ä‘á»™ X, Y
    def convert_coordinates(data: Dict[str, Any], html: str) -> Dict[str, Any]:
        """Convert coordinates from XY to lat/lon"""
        x_value = find(r'name="[^"]*MAP_X"[^>]*value="([^"]*)"', html)
        y_value = find(r'name="[^"]*MAP_Y"[^>]*value="([^"]*)"', html)
        
        if x_value and y_value:
            try:
                x, y = float(x_value), float(y_value)
                lat, lon = xy_to_latlon_tokyo(x, y)
                
                data.update({
                    'map_lat': str(lat),
                    'map_lng': str(lon)
                })
                
                print(f"ğŸ—ºï¸ Converted: X={x}, Y={y} â†’ Lat={lat:.6f}, Lng={lon:.6f}")
                
            except (ValueError, Exception) as e:
                print(f"âŒ Coordinate conversion error: {e}")
        
        return data
    
    # Xá»­ lÃ½ trÆ°á»›c khi dÃ¹ng
    def pass_html(html: str, data: Dict[str, Any]) -> tuple:
        """Clean HTML before processing with cached regex"""
        # Remove related sections
        related_pattern = compile_regex(r'<section[^>]*class="[^"]*--related[^"]*"[^>]*>.*?</section>')
        html = related_pattern.sub('', html)
        
        # Remove Japanese related properties text
        japanese_pattern = compile_regex(r'ã“ã®éƒ¨å±‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ãŸäººã¯ã€ã“ã‚“ãªéƒ¨å±‹ã‚‚ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ã¾ã™ã€‚.*?(?=<footer|$)')
        html = japanese_pattern.sub('', html)
        
        data['_html'] = html
        return html, data
    
    # Xá»­ lÃ½ cho hÃ¬nh áº£nh
    def get_gallery_images(html: str) -> Tuple[list, list, list]:
        """Extract gallery images with optimized request handling"""
        floorplan_images = []
        exterior_images = []
        interior_images = []
        
        # 1. Floor plan
        firstfloor_url = find(r'RF_firstfloorplan_photo\s*=\s*["\']([^"\']+)["\']', html)
        if firstfloor_url and firstfloor_url != "null":
            floorplan_images.append(firstfloor_url)

        # 2. Gallery
        gallery_url = find(r'RF_gallery_url\s*=\s*["\']([^"\']+)["\']', html)
        if not gallery_url or gallery_url == "null":
            return exterior_images, floorplan_images, interior_images
        
        try:
            print(f"ğŸ–¼ï¸ Fetching gallery: {gallery_url}")
            response = session.get(gallery_url, timeout=GALLERY_TIMEOUT)
            
            if response.status_code != 200:
                print(f"âŒ Gallery fetch failed: HTTP {response.status_code}")
                return exterior_images, floorplan_images, interior_images
            
            gallery_data = response.json()
            for item in gallery_data:
                filename = item.get("filename", "")
                if not filename:
                    continue
                    
                room_no = item.get("ROOM_NO", 0)
                if room_no == 99999 and not exterior_images:
                    exterior_images.append(filename)
                else:
                    interior_images.append(filename)
                    
        except requests.exceptions.Timeout:
            print("â° Gallery request timeout")
        except Exception as e:
            print(f"âŒ Gallery request error: {e}")
        
        return exterior_images, floorplan_images, interior_images
    
    def extract_image(data: Dict[str, Any], html: str) -> Dict[str, Any]:
        images_list = []
        used_urls = set()
        used_names = set()

        def add_image(img_url: str, category: str) -> bool:
            """Add image if not duplicate and under limit"""
            if (len(images_list) >= MAX_IMAGES or 
                img_url in used_urls or 
                img_url.split('/')[-1] in used_names):
                return False

            images_list.append({'url': img_url, 'category': category})
            used_urls.add(img_url)
            used_names.add(img_url.split('/')[-1])
            return True

        try:
            exterior_images, floorplan_images, interior_images = get_gallery_images(html)

            # Exterior â†’ láº¥y Ä‘Ãºng 1 áº£nh
            if exterior_images:
                add_image(exterior_images[0], "exterior")

            # Floorplan â†’ láº¥y Ä‘Ãºng 1 áº£nh
            if floorplan_images:
                add_image(floorplan_images[0], "floorplan")

            # Interior â†’ láº¥y nhiá»u cho Ä‘áº¿n khi Ä‘á»§ MAX_IMAGES
            for img_url in interior_images:
                print("print", img_url)
                add_image(img_url, "interior")

        except Exception as e:
            print(f"âŒ Image extraction error: {e}")

        if images_list:
            data['images'] = images_list
            print(f"ğŸ¯ Total images: {len(images_list)}")

        return data

    
    # CÃ¡c thÃ´ng sá»‘ máº·c Ä‘á»‹nh
    def set_default_amenities(data: Dict[str, Any], html: str) -> Dict[str, Any]:
        """Set default amenities using global constants"""
        data.update(DEFAULT_AMENITIES)
        return data
    
    # Xá»­ lÃ½ tiá»n
    def process_pricing(data: Dict[str, Any], html: str) -> Dict[str, Any]:
        """Process pricing calculations with validation"""
        if not all(key in data for key in ['monthly_rent', 'monthly_maintenance']):
            return data

        try:
            monthly_rent = data['monthly_rent']
            monthly_maintenance = data['monthly_maintenance']
            total_monthly = monthly_rent + monthly_maintenance

            if total_monthly > 0:
                data.update({
                    "total_monthly": total_monthly,
                    "numeric_guarantor": total_monthly * 50 // 100,
                    "numeric_guarantor_max": total_monthly * 80 // 100,
                })
                
                print(f"ğŸ’° Calculated pricing: total={total_monthly}å††")
            else:
                print(f"âš ï¸ Invalid total monthly amount: {total_monthly}")

        except Exception as e:
            print(f"âŒ Error processing pricing: {e}")

        return data
    
    # LÃ m sáº¡ch cÃ¡c biáº¿n temp
    def cleanup_temp_fields(data: Dict[str, Any], html: str) -> Dict[str, Any]:
        """Remove temporary fields that shouldn't be in final JSON"""
        if '_html' in data:
            del data['_html']
            print("ğŸ§¹ Cleaned up temporary _html field")
        return data
    
    # Xá»­ lÃ½ ná»™i dung tÄ©nh - Optimized with modular approach
    def extract_header_info(data: Dict[str, Any], html: str):
        """Extract building name, floor, and room number"""
        try:
            h1_content = find(r'<h1[^>]*>(.*?)</h1>', html)
            if not h1_content:
                print("âš ï¸ No h1 tag found")
                return
            
            h1_text = clean_html(h1_content)
            pattern = compile_regex(r'^(.+?)\s+(\d+)éš(\d+)$')
            match = pattern.match(h1_text)
            
            if match:
                data.update({
                    'building_name_ja': match.group(1).strip(),
                    'floor_no': int(match.group(2)),
                    'room_no': int(match.group(3))
                })
            else:
               data.update({
                    'building_name_ja': h1_text,
                })
                
        except Exception as e:
            print(f"âŒ Error extracting header info: {e}")
            
    def extract_available_from(data: Dict[str, Any], html: str):
        '''
        TÃ¬m å…¥å±…å¯èƒ½æ—¥ vÃ  ná»™i dung tháº» dd sau nÃ³ lÆ°u vÃ o available_from
        '''
        try:
            # TÃ¬m tháº» dt chá»©a "å…¥å±…å¯èƒ½æ—¥" vÃ  tháº» dd ngay sau nÃ³
            available_from_content = find(r'<dt[^>]*>å…¥å±…å¯èƒ½æ—¥</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not available_from_content:
                print("âš ï¸ No available_from section found")
                return
            
            # LÃ m sáº¡ch HTML vÃ  láº¥y text
            available_from_text = clean_html(available_from_content)
            if available_from_text:
                data['available_from'] = available_from_text
                print(f"ğŸ“… Set available_from: {available_from_text}")
            else:
                print("âš ï¸ Available_from content is empty after cleaning")
                
        except Exception as e:
            print(f"âŒ Error extracting available_from: {e}")
    
    def extract_address_info(data: Dict[str, Any], html: str):
        """Extract address information"""
        try:
            address_section = find(r'<dt[^>]*>æ‰€åœ¨åœ°</dt>(.*?)(?=<dt|</dl>|$)', html)
            if not address_section:
                print("âš ï¸ No address section found")
                return
            
            dd_pattern = compile_regex(r'<dd[^>]*>(.*?)</dd>')
            dd_matches = dd_pattern.findall(address_section)
            
            if len(dd_matches) >= 2:
                address_text = clean_html(dd_matches[1])
                address_parts = parse_japanese_address(address_text)
                
                data['address'] = address_text
                if address_parts['chome_banchi']:
                    data['chome_banchi'] = address_parts['chome_banchi']
                
                print(f"ğŸ  Set address: {address_text}")
            else:
                print(f"âš ï¸ Found {len(dd_matches)} dd tags, expected at least 2")
                
        except Exception as e:
            print(f"âŒ Error extracting address info: {e}")
    
    def extract_rent_info(data: Dict[str, Any], html: str):
        """Extract rent information"""
        try:
            rent_pattern = compile_regex(r'class="[^"]*__rent[^"]*"[^>]*>(.*?)</[^>]+>')
            rent_match = rent_pattern.search(html)
            
            if not rent_match:
                print("âš ï¸ No rent class found")
                return
            
            rent_text = clean_html(rent_match.group(1))
            print(f"ğŸ  Found rent text: {rent_text}")
            
            # Extract rent and maintenance fees
            price_pattern = compile_regex(r'([\d,]+)å††(?:\s*/\s*([\d,]+)å††)?')
            price_match = price_pattern.search(rent_text)
            
            if price_match:
                monthly_rent = int(price_match.group(1).replace(',', ''))
                monthly_maintenance = int(price_match.group(2).replace(',', '')) if price_match.group(2) else 0
                
                data.update({
                    'monthly_rent': monthly_rent,
                    'monthly_maintenance': monthly_maintenance
                })
                
                print(f"ğŸ’° Extracted rent: {monthly_rent}å††, maintenance: {monthly_maintenance}å††")
            else:
                print(f"âš ï¸ Rent format not matched: {rent_text}")
                
        except Exception as e:
            print(f"âŒ Error extracting rent info: {e}")
    
    def extract_deposit_key_info(data: Dict[str, Any], html: str):
        """Extract deposit and key money information"""
        try:
            deposit_key_content = find(r'<dt[^>]*>æ•·é‡‘ï¼ç¤¼é‡‘</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not deposit_key_content:
                print("âš ï¸ No deposit/key section found")
                return
            
            deposit_key_text = clean_html(deposit_key_content)
            print(f"ğŸ’° Found deposit/key info: {deposit_key_text}")
            
            pattern = compile_regex(r'([\d.]+)ãƒ¶æœˆ\s*/\s*([\d.]+)ãƒ¶æœˆ')
            match = pattern.search(deposit_key_text)
            
            if match:
                data.update({
                    'numeric_deposit': float(match.group(1)),
                    'numeric_key': float(match.group(2))
                })
                
        except Exception as e:
            print(f"âŒ Error extracting deposit/key info: {e}")
    
    def extract_room_info(data: Dict[str, Any], html: str):
        """Extract room type and size"""
        try:
            room_info_content = find(r'<dt[^>]*>é–“å–ã‚Šãƒ»é¢ç©</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not room_info_content:
                print("âš ï¸ No room info section found")
                return
            
            room_info_text = clean_html(room_info_content)
            pattern = compile_regex(r'^([^/]+?)\s*/\s*([\d.]+)ã¡')
            match = pattern.search(room_info_text)
            
            if match:
                room_type = re.sub(r'[^\w]', '', match.group(1).strip())
                size = float(match.group(2))
                
                data.update({
                    'room_type': room_type,
                    'size': size
                })
                
        except Exception as e:
            print(f"âŒ Error extracting room info: {e}")
    
    def extract_construction_date(data: Dict[str, Any], html: str):
        """Extract construction date"""
        try:
            construction_content = find(r'<dt[^>]*>ç«£å·¥æ—¥</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not construction_content:
                print("âš ï¸ No construction date section found")
                return
            
            construction_text = clean_html(construction_content)
            year_pattern = compile_regex(r'(\d{4})å¹´')
            year_match = year_pattern.search(construction_text)
            
            if year_match:
                data['year'] = int(year_match.group(1))
            else:
                print(f"âš ï¸ Could not extract year from: {construction_text}")
                
        except Exception as e:
            print(f"âŒ Error extracting construction date: {e}")
    
    def extract_structure_info(data: Dict[str, Any], html: str):
        """Extract building structure information"""
        try:
            structure_content = find(r'<dt[^>]*>è¦æ¨¡æ§‹é€ </dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not structure_content:
                print("âš ï¸ No structure section found")
                return
            
            structure_text = clean_html(structure_content)
            print(f"ğŸ—ï¸ Structure text: '{structure_text}'")
            
            pattern = compile_regex(r'^(.*?é€ )\s*åœ°ä¸Š(\d+)éš(?:åœ°ä¸‹(\d+)éšå»º?)?')
            match = pattern.search(structure_text)
            
            if match:
                data.update({
                    'structure': match.group(1).strip(),
                    'floors': int(match.group(2))
                })
                
                if match.group(3):
                    data['basement_floors'] = int(match.group(3))
                    
                print(f"ğŸ—ï¸ Extracted structure info successfully")
            else:
                print(f"âš ï¸ Structure pattern did not match: '{structure_text}'")
                
        except Exception as e:
            print(f"âŒ Error extracting structure info: {e}")
    
    def extract_renewal_fee(data: Dict[str, Any], html: str):
        """Extract renewal fee information"""
        try:
            renewal_content = find(r'<dt[^>]*>æ›´æ–°æ–™</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not renewal_content:
                print("âš ï¸ No renewal fee section found")
                return
            
            renewal_text = clean_html(renewal_content)
            pattern = compile_regex(r'æ–°è³ƒæ–™ã®(\d+)ãƒ¶æœˆåˆ†')
            match = pattern.search(renewal_text)
            
            if match:
                months = int(match.group(1))
                data.update({
                    'renewal_new_rent': 'Y',
                    'months_renewal': 12 if months == 1 else months
                })
                
        except Exception as e:
            print(f"âŒ Error extracting renewal fee: {e}")
    
    def extract_direction_info(data: Dict[str, Any], html: str):
        """Extract apartment facing direction"""
        try:
            direction_content = find(r'<dt[^>]*>æ–¹ä½</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not direction_content:
                print("âš ï¸ No direction section found")
                return
            
            direction_text = clean_html(direction_content)
            
            for jp_direction, field_name in DIRECTION_MAPPING.items():
                if jp_direction in direction_text:
                    data[field_name] = 'Y'
                    break
            else:
                print(f"âš ï¸ No recognizable directions found in: {direction_text}")
                
        except Exception as e:
            print(f"âŒ Error extracting direction info: {e}")
    
    def extract_lock_exchange(data: Dict[str, Any], html: str):
        """Extract lock exchange fee"""
        try:
            other_fees_content = find(r'<dt[^>]*>ãã®ä»–è²»ç”¨</dt>\s*<dd[^>]*>(.*?)</dd>', html)
            if not other_fees_content:
                print("âš ï¸ No other fees section found")
                return
            
            other_fees_text = clean_html(other_fees_content)
            pattern = compile_regex(r'ç„é–¢éŒ äº¤æ›ä»£[^\d]*([\d,]+)å††')
            match = pattern.search(other_fees_text)
            
            if match:
                data['lock_exchange'] = int(match.group(1).replace(',', ''))
                
        except Exception as e:
            print(f"âŒ Error extracting lock exchange: {e}")
    
    def extract_amenities(data: Dict[str, Any], html: str):
        """Extract amenities information"""
        try:
            amenities_pattern = compile_regex(r'<dt[^>]*>å°‚æœ‰éƒ¨ãƒ»å…±ç”¨éƒ¨è¨­å‚™</dt>\s*<dd[^>]*>(.*?)</dd>')
            amenities_match = amenities_pattern.search(html)
            
            if not amenities_match:
                print("âš ï¸ No amenities section found")
                return
            
            amenities_text = clean_html(amenities_match.group(1))
            print(f"ğŸ¢ Found amenities info: {amenities_text}")
            
            found_amenities = []
            for jp_amenity, field_name in AMENITIES_MAPPING.items():
                if jp_amenity in amenities_text:
                    data[field_name] = 'Y'
                    found_amenities.append(f"{jp_amenity} â†’ {field_name}")
            
            if found_amenities:
                print(f"ğŸ¢ Set amenities to Y:")
                for amenity in found_amenities:
                    print(f"   {amenity}")
            else:
                print(f"âš ï¸ No recognizable amenities found")
                
        except Exception as e:
            print(f"âŒ Error extracting amenities: {e}")
    
    def extract_building_description(data: Dict[str, Any], html: str):
        """Extract building description"""
        try:
            description_pattern = compile_regex(r'<dt[^>]*>å‚™è€ƒ</dt>\s*<dd[^>]*>(.*?)</dd>')
            description_match = description_pattern.search(html)
            
            if description_match:
                description_text = clean_html(description_match.group(1))
                if description_text:
                    data['building_description_ja'] = description_text
                    
        except Exception as e:
            print(f"âŒ Error extracting building description: {e}")
    
    def get_static_info(data: Dict[str, Any], html: str) -> Dict[str, Any]:
        """Process static information extraction using modular approach"""
        # Process each section using dedicated functions
        extract_header_info(data, html)
        extract_available_from(data, html)
        extract_address_info(data, html)
        extract_rent_info(data, html)
        extract_deposit_key_info(data, html)
        extract_room_info(data, html)
        extract_construction_date(data, html)
        extract_structure_info(data, html)
        extract_renewal_fee(data, html)
        extract_direction_info(data, html)
        extract_lock_exchange(data, html)
        extract_amenities(data, html)
        extract_building_description(data, html)
        
        return data
    
    # Setup hooks
    extractor.add_pre_hook(pass_html)
    
    # Add processors in order
    processors = [
        extract_image,
        get_static_info,
        convert_coordinates, 
        set_default_amenities,
        process_pricing,
        cleanup_temp_fields,
    ]
    
    for processor in processors:
        extractor.add_post_hook(safe_wrapper(processor))
    
    return extractor